{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7e51b5f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e51b5f0",
        "outputId": "1f88e175-0908-405d-9efe-03fe5c9dea8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import os\n",
        "from torch_geometric.data import Dataset, download_url, Data\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from torch_geometric import nn as gnn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import crop\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from timm.models.helpers import load_pretrained\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "from torch.nn import Sequential as Seq\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.append('/home/paulraae/MS_Thesis/ViG_based_link_pred_implementation')\n",
        "from onegraph_rest_free_graphds import OneGraphDS\n",
        "from gan_based_models import Discriminator\n",
        "from second_stage_vig_based_models import FullModel\n",
        "from vig_based_functions import act_layer, get_multi_shot_set\n",
        "from vig_graph_modules import GraphEncoderBlockSE, GrapherSetEdges\n",
        "from perceptual_loss import VGGPerceptualLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a74335bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a74335bb",
        "outputId": "2b605960-2fb8-425b-a376-c46e572966f9"
      },
      "outputs": [],
      "source": [
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/test_202_with_tiles_processed.pk1', 'rb') as handle:\n",
        "    data = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bd504e50",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/all_patch_distances.pk1', 'rb') as handle:\n",
        "    patch_distances = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u9OMCSEDgagj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9OMCSEDgagj",
        "outputId": "e9b643ea-9a70-4f71-ae5e-f6160b039f1f"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(data[\"tile_cluster\"], return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jA2-i71tg7rN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA2-i71tg7rN",
        "outputId": "acdb5957-1b31-470e-fc82-6a3b289774be"
      },
      "outputs": [],
      "source": [
        "data[\"all_tiles\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8840ed26",
      "metadata": {},
      "source": [
        "# LW Ind Implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1b2859a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "A, T, _, _, _ = data[\"tiles\"].shape\n",
        "\n",
        "lw_ind = np.where(np.array([np.sum(x == 255)/(56*56*3) for x in data[\"all_tiles\"]]) <=0.4)[0]\n",
        "\n",
        "pos_ind = [[x for x in range(T)] for _ in range(A)]\n",
        "pos_ind = torch.Tensor(np.array(pos_ind)).flatten().to(torch.int)\n",
        "pos_ind = pos_ind[lw_ind]\n",
        "\n",
        "lw_ind = lw_ind[np.where(pos_ind != 0)[0]]\n",
        "\n",
        "pos_ind = [[x for x in range(T)] for _ in range(A)]\n",
        "pos_ind = torch.Tensor(np.array(pos_ind)).flatten().to(torch.int)\n",
        "pos_ind = pos_ind[lw_ind]\n",
        "\n",
        "lw_ind = lw_ind[np.where(pos_ind != 3)[0]]\n",
        "\n",
        "pos_ind = [[x for x in range(T)] for _ in range(A)]\n",
        "pos_ind = torch.Tensor(np.array(pos_ind)).flatten().to(torch.int)\n",
        "pos_ind = pos_ind[lw_ind]\n",
        "\n",
        "lw_ind = lw_ind[np.where(pos_ind != 12)[0]]\n",
        "\n",
        "pos_ind = [[x for x in range(T)] for _ in range(A)]\n",
        "pos_ind = torch.Tensor(np.array(pos_ind)).flatten().to(torch.int)\n",
        "pos_ind = pos_ind[lw_ind]\n",
        "\n",
        "lw_ind = lw_ind[np.where(pos_ind != 15)[0]]\n",
        "\n",
        "pos_ind = [[x for x in range(T)] for _ in range(A)]\n",
        "pos_ind = torch.Tensor(np.array(pos_ind)).flatten().to(torch.int)\n",
        "pos_ind = pos_ind[lw_ind]\n",
        "data[\"tile_cluster\"] = data[\"tile_cluster\"][lw_ind]\n",
        "data[\"all_tiles\"] = data[\"all_tiles\"][lw_ind]\n",
        "\n",
        "img_ind = [[x for _ in range(T)] for x in range(A)]\n",
        "\n",
        "img_ind = torch.Tensor(np.array(img_ind)).flatten().to(torch.int)\n",
        "\n",
        "img_ind = img_ind[lw_ind]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd3dbad",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(lw_ind.shape)\n",
        "print(pos_ind.shape)\n",
        "print(img_ind.shape)\n",
        "print(data[\"tile_cluster\"].shape)\n",
        "print(data[\"all_tiles\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9501783f",
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(data[\"tile_cluster\"], return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e4e889",
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(pos_ind, return_counts=True)\n",
        "for x in zip(unique, counts):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973e68ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(img_ind, return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adf418a8",
      "metadata": {},
      "source": [
        "## Remove White Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7239fbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "ind = np.where(data[\"tile_cluster\"][lw_ind] != 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034ba428",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_ind = np.where(data[\"tile_cluster\"] == 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6779f3be",
      "metadata": {},
      "outputs": [],
      "source": [
        "n=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3f85dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"all_tiles\"][ind].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2fc30c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "per = np.sum(data[\"all_tiles\"][ind] == 255)/(56*56*3*1824)\n",
        "per*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27b4d9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = []\n",
        "for x in data[\"all_tiles\"][ind]:\n",
        "    hist.append(np.sum(x == 255)/(56*56*3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5a2e16",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(np.quantile(hist, 0.25))\n",
        "print(np.quantile(hist, 0.75))\n",
        "plt.boxplot(hist)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f09822",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(hist, density=True, bins = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "081a85b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "n += 1\n",
        "print(100*(np.sum(data[\"all_tiles\"][ind][n] == 255)/(56*56*3)))\n",
        "plt.imshow(data[\"all_tiles\"][ind][n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0823fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "lw_ind = np.where(np.array([np.sum(x == 255)/(56*56*3) for x in data[\"all_tiles\"]]) <=0.75)[0]\n",
        "print(lw_ind.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9f0e7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "n=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20239583",
      "metadata": {},
      "outputs": [],
      "source": [
        "n += 1\n",
        "print(n)\n",
        "print(100*(np.sum(data[\"all_tiles\"][lw_ind][n] == 255)/(56*56*3)))\n",
        "plt.imshow(data[\"all_tiles\"][lw_ind][n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a38351b",
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"tile_images\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6e46dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(data[\"tile_cluster\"], return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f67ff5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(data[\"tile_cluster\"][lw_ind], return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71b05542",
      "metadata": {},
      "source": [
        "## Pre-Calculate path distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9552e933",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "class VGGPerceptualLoss(torch.nn.Module):\n",
        "    def __init__(self, resize=True):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        blocks = []\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[:4].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[4:9].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[9:16].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[16:23].eval())\n",
        "        self.blocks = torch.nn.ModuleList(blocks)\n",
        "        self.transform = torch.nn.functional.interpolate\n",
        "        self.resize = resize\n",
        "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
        "\n",
        "    def forward(self, input, target, feature_layers=[0, 1, 2, 3], style_layers=[]):\n",
        "        if input.shape[1] != 3:\n",
        "            input = input.repeat(1, 3, 1, 1)\n",
        "            target = target.repeat(1, 3, 1, 1)\n",
        "        input = (input-self.mean) / self.std\n",
        "        target = (target-self.mean) / self.std\n",
        "        if self.resize:\n",
        "            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "        loss = 0.0\n",
        "        x = input\n",
        "        y = target\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            y = block(y)\n",
        "            if i in feature_layers:\n",
        "                loss += torch.nn.functional.l1_loss(x, y)\n",
        "            if i in style_layers:\n",
        "                act_x = x.reshape(x.shape[0], x.shape[1], -1)\n",
        "                act_y = y.reshape(y.shape[0], y.shape[1], -1)\n",
        "                gram_x = act_x @ act_x.permute(0, 2, 1)\n",
        "                gram_y = act_y @ act_y.permute(0, 2, 1)\n",
        "                loss += torch.nn.functional.l1_loss(gram_x, gram_y)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f262ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"all_tiles\"] = torch.Tensor(data[\"all_tiles\"]/255)\n",
        "data[\"all_tiles\"] = data[\"all_tiles\"].to(\"cuda:7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cb3cf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"all_tiles\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb8910a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "dist = VGGPerceptualLoss().to(\"cuda:7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef873390",
      "metadata": {},
      "outputs": [],
      "source": [
        "l = dist(train_tiles[0].reshape(1,3,56,56), train_tiles[10].reshape(1,3,56,56))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c814c86",
      "metadata": {},
      "outputs": [],
      "source": [
        "l.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adaff9ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "per_distances = []\n",
        "euc_distances = []\n",
        "N_SHOTS = 2\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    for avg in tqdm(data[\"all_tiles\"]):\n",
        "        i += 1\n",
        "        per_aux = []\n",
        "        euc_aux = []\n",
        "        for img in tqdm(data[\"all_tiles\"][i:]):\n",
        "            per_aux.append(dist(avg.reshape(1,3,56,56), img.reshape(1,3,56,56), feature_layers=[0, 1, 2, 3]))\n",
        "            euc_aux.append(torch.dist(avg, img))\n",
        "        \n",
        "        per_aux = torch.Tensor(per_aux)\n",
        "        per_distances.append(per_aux)\n",
        "        \n",
        "        euc_aux = torch.Tensor(euc_aux)\n",
        "        euc_distances.append(euc_aux)\n",
        "        \n",
        "        del per_aux, euc_aux\n",
        "        \n",
        "\n",
        "    #distances = torch.Tensor(distances)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330289e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "patch_distances = {\"perception_distances\":per_distances, \"euclidean_distances\":euc_distances}\n",
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/all_patch_distances.pk1', 'wb') as handle:\n",
        "    pickle.dump(patch_distances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/all_patch_distances_backup.pk1', 'wb') as handle:\n",
        "    pickle.dump(patch_distances, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4bfd06c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(per_distances))\n",
        "print(len(euc_distances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1e872f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(per_distances[1039])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50dcbe1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "\"\"\"\n",
        "the following python list is populated by tensors that represent the upper triangle of a distance matrix (position 0,300 is the distance between nodes 0 and 300 but 300,0 does not exist as that would be part of the lower triangle). This means that each tensor in the array is of a different length (each succesive tensor is 1 value smaller as that distance value is captured in the tensors above it), which means the full array cannot be converted to a torch tensor. Write a code that fills out the matrix with all distances both upper and lower triangles (both 0,300 and 300,0 should have the same value ie the distance between nodes 0 and 300). Diagonals should be 0 as these would be the distances between a node and itself. When appending a row, the difference in length of each tensor must be fixed before appending into the full matrix. The array's name is - patch_distances[\"perception_distances\"]\n",
        "\n",
        "\n",
        "\n",
        "do not include comments, code explanations etc only just the code that does the function required\n",
        "\n",
        "This error coming up due to not fixing the tensor length, that is, not making up for the distances covered in the above tensors for 1 tensor\n",
        "\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------RuntimeError Traceback (most recent call last)Cell In[72], line 6 3 full_matrix = torch.zeros((num_nodes, num_nodes), device=data_list[0].device, dtype=data_list[0].dtype) 5 for i, row_data in enumerate(data_list):----> 6 full_matrix[i, i+1:] = row_data 7 full_matrix[i+1:, i] = row_dataRuntimeError: The expanded size of the tensor (1039) must match the existing size (1038) at non-singleton dimension 0. Target sizes: [1039]. Tensor sizes: [1038]\n",
        "\"\"\"\n",
        "\n",
        "data_list = patch_distances[\"perception_distances\"]\n",
        "num_nodes = len(data_list[0]) + 1\n",
        "full_matrix_per = torch.zeros((num_nodes, num_nodes), device=data_list[0].device, dtype=data_list[0].dtype)\n",
        "\n",
        "for i, row_data in enumerate(data_list):\n",
        "    n = row_data.size(0)\n",
        "    full_matrix_per[i, num_nodes-n:] = row_data\n",
        "    full_matrix_per[num_nodes-n:, i] = row_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae454ae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_list = patch_distances[\"euclidean_distances\"]\n",
        "num_nodes = len(data_list[0]) + 1\n",
        "full_matrix_euc = torch.zeros((num_nodes, num_nodes), device=data_list[0].device, dtype=data_list[0].dtype)\n",
        "\n",
        "for i, row_data in enumerate(data_list):\n",
        "    n = row_data.size(0)\n",
        "    full_matrix_euc[i, num_nodes-n:] = row_data\n",
        "    full_matrix_euc[num_nodes-n:, i] = row_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef1f3fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.equal(full_matrix_euc, full_matrix_euc.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3d55ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "full_matrix_per.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0b3e9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "patch_distances = {\"perception_distances\":full_matrix_per, \"euclidean_distances\":full_matrix_euc}\n",
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/all_patch_distances.pk1', 'wb') as handle:\n",
        "    pickle.dump(patch_distances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/home/paulraae/MS_Thesis_Data/tester_eye_data/all_patch_distances_backup.pk1', 'wb') as handle:\n",
        "    pickle.dump(patch_distances, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3aeef4",
      "metadata": {},
      "outputs": [],
      "source": [
        "del dist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a21ef65",
      "metadata": {},
      "source": [
        "## Dist Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2122be58",
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = []\n",
        "N_SHOTS = 2\n",
        "i += 1\n",
        "with torch.no_grad():\n",
        "    avg = data[\"all_tiles\"][i]\n",
        "    search_cluster = data[\"tile_cluster\"][i]\n",
        "    cluster_space = np.where(data[\"tile_cluster\"] == search_cluster)[0]\n",
        "    for img in tqdm(data[\"all_tiles\"][cluster_space]):\n",
        "        distances.append(dist(avg.reshape(1,3,56,56), img.reshape(1,3,56,56), feature_layers=[0, 1, 2, 3]))\n",
        "        \n",
        "\n",
        "    distances = torch.Tensor(distances)\n",
        "    values, indices = torch.topk(distances, N_SHOTS+1, largest=False, sorted=True)\n",
        "    \n",
        "print(cluster_space[indices])\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "axes[0].imshow(data[\"all_tiles\"][i].cpu().detach().numpy())\n",
        "axes[0].set_title(str(data[\"tile_cluster\"][i]))\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(data[\"all_tiles\"][cluster_space[indices][1]].cpu().detach().numpy())\n",
        "axes[1].set_title(str(data[\"tile_cluster\"][cluster_space[indices][1]]))\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(data[\"all_tiles\"][cluster_space[indices][2]].cpu().detach().numpy())\n",
        "axes[2].set_title(str(data[\"tile_cluster\"][cluster_space[indices][2]]))\n",
        "axes[2].axis('off')\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3253fc42",
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = []\n",
        "N_SHOTS = 2\n",
        "#i += 1\n",
        "with torch.no_grad():\n",
        "    avg = data[\"all_tiles\"][i]\n",
        "    for img in tqdm(data[\"all_tiles\"]):\n",
        "        distances.append(dist(avg.reshape(1,3,56,56), img.reshape(1,3,56,56), feature_layers=[0, 1]))\n",
        "        \n",
        "\n",
        "    distances = torch.Tensor(distances)\n",
        "    values, indices = torch.topk(distances, N_SHOTS+1, largest=False, sorted=True)\n",
        "    \n",
        "print(indices)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "axes[0].imshow(data[\"all_tiles\"][i].cpu().detach().numpy())\n",
        "axes[0].set_title(str(data[\"tile_cluster\"][i]))\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(data[\"all_tiles\"][indices][1].cpu().detach().numpy())\n",
        "axes[1].set_title(str(data[\"tile_cluster\"][indices][1]))\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(data[\"all_tiles\"][indices][2].cpu().detach().numpy())\n",
        "axes[2].set_title(str(data[\"tile_cluster\"][indices][2]))\n",
        "axes[2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ba0a37",
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = []\n",
        "N_SHOTS = 2\n",
        "#i += 1\n",
        "with torch.no_grad():\n",
        "    avg = data[\"all_tiles\"][i]\n",
        "    search_cluster = data[\"tile_cluster\"][i]\n",
        "    cluster_space = np.where(data[\"tile_cluster\"] == search_cluster)[0]\n",
        "    for img in data[\"all_tiles\"][cluster_space]:\n",
        "        distances.append(torch.dist(avg, img))\n",
        "        \n",
        "\n",
        "    distances = torch.Tensor(distances)\n",
        "    values, indices = torch.topk(distances, N_SHOTS+1, largest=False, sorted=True)\n",
        "    \n",
        "print(cluster_space[indices])\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "axes[0].imshow(data[\"all_tiles\"][i].cpu().detach().numpy())\n",
        "axes[0].set_title(str(data[\"tile_cluster\"][i]))\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(data[\"all_tiles\"][cluster_space[indices][1]].cpu().detach().numpy())\n",
        "axes[1].set_title(str(data[\"tile_cluster\"][cluster_space[indices][1]]))\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(data[\"all_tiles\"][cluster_space[indices][2]].cpu().detach().numpy())\n",
        "axes[2].set_title(str(data[\"tile_cluster\"][cluster_space[indices][2]]))\n",
        "axes[2].axis('off')\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf839898",
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = []\n",
        "N_SHOTS = 2\n",
        "#i += 1\n",
        "with torch.no_grad():\n",
        "    avg = data[\"all_tiles\"][i]\n",
        "    for img in data[\"all_tiles\"]:\n",
        "        distances.append(torch.dist(avg, img))\n",
        "        \n",
        "\n",
        "    distances = torch.Tensor(distances)\n",
        "    values, indices = torch.topk(distances, N_SHOTS+1, largest=False, sorted=True)\n",
        "    \n",
        "print(indices)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "axes[0].imshow(data[\"all_tiles\"][i].cpu().detach().numpy())\n",
        "axes[0].set_title(str(data[\"tile_cluster\"][i]))\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(data[\"all_tiles\"][indices][1].cpu().detach().numpy())\n",
        "axes[1].set_title(str(data[\"tile_cluster\"][indices][1]))\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(data[\"all_tiles\"][indices][2].cpu().detach().numpy())\n",
        "axes[2].set_title(str(data[\"tile_cluster\"][indices][2]))\n",
        "axes[2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e697237",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "O53yijsh4-AB",
      "metadata": {
        "id": "O53yijsh4-AB"
      },
      "outputs": [],
      "source": [
        "NUM_SAMPLES_PER_GRAPH = 100\n",
        "NUM_LINES = 4\n",
        "NUM_NEIGHBORS = 5\n",
        "NUM_BLOCK_LOOPS = 2\n",
        "NUM_BLOCKS_PER_HEAD = 2\n",
        "EDGE_METHOD = \"KNN\"\n",
        "DELETION_THRESHOLD = 0.5\n",
        "GET_BASE_TILES = True\n",
        "N_SHOTS = 2\n",
        "DEVICE = \"cuda:7\" if torch.cuda.is_available() else \"cpu\"\n",
        "ATTENTION_HEADS = 4\n",
        "ACTIVATION_TYPE = \"relu\"\n",
        "\n",
        "EPOCHS = 200\n",
        "LR = 0.0001\n",
        "D_LR = 0.0001\n",
        "BATCH_SIZE = 100\n",
        "K = 2\n",
        "KP = 5\n",
        "REAL_LABEL = 1\n",
        "FAKE_LABEL = 0\n",
        "SWITCH_THRESHOLD = -1\n",
        "\n",
        "NUM_GRAPH_NODES = 600\n",
        "\n",
        "GAN_FREQ = 1\n",
        "GAN_DISC_FREQ = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5048f65c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:7'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "RyT74N-U7hE2",
      "metadata": {
        "id": "RyT74N-U7hE2"
      },
      "outputs": [],
      "source": [
        "train_images = torch.Tensor(data['image']).to(torch.float32)\n",
        "train_images = (train_images - torch.min(train_images))/(torch.max(train_images) - torch.min(train_images))\n",
        "\n",
        "train_tiles = torch.Tensor(data['all_tiles']).to(torch.float32)\n",
        "train_tiles = (train_tiles - torch.min(train_tiles))/(torch.max(train_tiles) - torch.min(train_tiles))\n",
        "\n",
        "train_tiles_clusters = torch.Tensor(data['tile_cluster']).to(torch.int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9cf6ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "i=0\n",
        "print(lw_ind[i])\n",
        "print(pos_ind[i])\n",
        "print(img_ind[i])\n",
        "print(train_tiles[i].shape)\n",
        "print(train_tiles_clusters[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c9f679f",
      "metadata": {},
      "source": [
        "# Gen Only model (Stage 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8b6ed68c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class InjectNoise(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn((x.shape[0], 1, x.shape[2], x.shape[3]), device=x.device)\n",
        "        return x + self.weight * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db719728",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GrapherSetEdges(nn.Module):\n",
        "    def __init__(self, in_channels, img_dim, drop_path=0.0, device = \"cuda:7\"):\n",
        "        super(GrapherSetEdges, self).__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "        )\n",
        "        self.graph_conv = gnn.GraphConv(in_channels*img_dim*img_dim, in_channels*img_dim*img_dim)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        _tmp = x\n",
        "        B,C,H,W = x.shape\n",
        "        x = self.fc1(x)\n",
        "        x = x.reshape(B,-1)\n",
        "        x = self.graph_conv(x, edge_index)\n",
        "        x = x.reshape(B,-1,H,W)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + _tmp\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "497cf4ab",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFFN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_features, act\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, drop_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, in_features, act='relu', drop_path=0.0):\n",
        "        super().__init__()\n",
        "        out_features = in_features\n",
        "        hidden_features = in_features\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_features, hidden_features, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(hidden_features),\n",
        "        )\n",
        "        self.act = act_layer(act)\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_features, out_features, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_features),\n",
        "        )\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + shortcut\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "edcb5992",
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_dim=3, out_channels=128, img_dim = 6, device=\"cuda:7\"):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_dim, out_channels, 3, stride=3, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            \n",
        "            nn.Conv2d(out_channels, out_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            \n",
        "            #nn.Conv2d(out_dim//2, out_dim, 3, stride=1, padding=1),\n",
        "        )\n",
        "        self.graphblock = GrapherSetEdges(out_channels, img_dim, device=device)\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.convs(x)\n",
        "        x = self.graphblock(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dab8c8e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GeneratorBlock(nn.Module):\n",
        "    def __init__(self, in_channels = 128, out_channels = 3, img_dim = 7, device=\"cuda:7\"):\n",
        "        super(GeneratorBlock, self).__init__()\n",
        "        self.graphblock = GrapherSetEdges(in_channels, img_dim, device=device)\n",
        "        self.inject_noise = InjectNoise(in_channels)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 3, 3, dilation = 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            \n",
        "            nn.Conv2d(out_channels, out_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace = True),\n",
        "            #nn.ConvTranspose2d(in_channels//8, out_channels, 1, 1, dilation = 1),\n",
        "            #nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.graphblock(x, edge_index)\n",
        "        x = self.inject_noise(x[0].unsqueeze(0))\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "69aa0480",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphUNET(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, img_dim, at_heads = 4, device = \"cuda:7\"):\n",
        "        super(GraphUNET, self).__init__()\n",
        "        self.encblock1 = EncoderBlock(in_channels, out_channels//2, img_dim*3)\n",
        "        self.encblock2 = EncoderBlock(out_channels//2, out_channels, img_dim)\n",
        "        \n",
        "        self.genblock2 = GeneratorBlock(out_channels, out_channels//2, img_dim, device)\n",
        "        self.genblock1 = GeneratorBlock(out_channels//2, out_channels//16, img_dim*3, device)\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(out_channels//16, in_channels, 1, 1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x, graph, edge_index):\n",
        "        r1 = self.encblock1(graph, edge_index[0])\n",
        "        r2 = self.encblock2(r1, edge_index[0])\n",
        "        \n",
        "        x = torch.cat([x,r2], dim = 0)\n",
        "        x = self.genblock2(x, edge_index[1])\n",
        "        x = torch.cat([x,r1], dim = 0)\n",
        "        x = self.genblock1(x, edge_index[1])\n",
        "        return self.out(x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a9ad2a1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/paulraae/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "edge_index = [torch.Tensor([[0,0],[1,2]]).to(torch.long).to(DEVICE),\n",
        "              torch.Tensor([[0,0,0],[1,2,3]]).to(torch.long).to(DEVICE)]\n",
        "loss = VGGPerceptualLoss().to(DEVICE)\n",
        "best = [0, np.Inf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "93da8468",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GraphUNET(3, 128, 6, 2, device = DEVICE)\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c53c179",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeafe415",
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/home/paulraae/MS_Thesis/ViG_based_link_pred_implementation/saved_models/1st_model.pickle\"\n",
        "model.load_state_dict(torch.load(SAVE_PATH, weights_only=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7bfed9bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    train_index = np.array([x for x in range(train_tiles.shape[0])])\n",
        "    np.random.shuffle(train_index)\n",
        "    train_index = train_index[:1000].reshape(-1, BATCH_SIZE)\n",
        "    for tr_ind in train_index:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        out = torch.topk(patch_distances[\"perception_distances\"][tr_ind], K+1, largest=False).indices\n",
        "        batch = train_tiles[out]\n",
        "        pred = []\n",
        "        for input in batch:\n",
        "            break\n",
        "        break\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe9b1c69",
      "metadata": {},
      "outputs": [],
      "source": [
        "tr_ind[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6a860b",
      "metadata": {},
      "outputs": [],
      "source": [
        "input = train_tiles[[1023,370,189]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc9891e",
      "metadata": {},
      "source": [
        "### Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd9d5d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/home/paulraae/MS_Thesis/ViG_based_link_pred_implementation/saved_models/1st_noise_model_more_train.pickle\"\n",
        "torch.save(model.state_dict(), SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be6bbfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/home/paulraae/MS_Thesis/ViG_based_link_pred_implementation/saved_models/1st_noise_model_more_train_backup.pickle\"\n",
        "torch.save(model.state_dict(), SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "483a66d7",
      "metadata": {},
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fdb9d078",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x300 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "axes[0].imshow(input[0].cpu())\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(input[1].cpu())\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(input[2].cpu())\n",
        "axes[2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ba68542b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 56, 56, 3])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "983fe2cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 64, 18, 18])\n",
            "torch.Size([3, 128, 6, 6])\n",
            "torch.Size([1, 128, 6, 6])\n",
            "torch.Size([3, 128, 6, 6])\n",
            "torch.Size([4, 128, 6, 6])\n",
            "torch.Size([4, 64, 18, 18])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(1, 128, 6, 6, device=DEVICE)\n",
        "    pred = model(noise, input.reshape(3,3,56,56).to(DEVICE), edge_index)\n",
        "    \n",
        "plt.imshow(pred.cpu().detach().numpy().reshape(56,56,3), cmap=\"grey\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4042b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "tr_ind = tr_ind.T.copy() \n",
        "tr_ind = torch.from_numpy(tr_ind).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be17877b",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_tiles[tr_ind].reshape(K+1, BATCH_SIZE, 3, 56, 56).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e2e4c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss(pred, train_tiles[tr_ind].reshape(K+1, BATCH_SIZE, 3, 56, 56))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b00139",
      "metadata": {},
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48ec476",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\",epoch)\n",
        "    running_loss = 0.0\n",
        "    train_index = np.array([x for x in range(train_tiles.shape[0])])\n",
        "    np.random.shuffle(train_index)\n",
        "    train_index = train_index[:1000].reshape(-1, BATCH_SIZE)\n",
        "    i=0\n",
        "    for tr_ind in tqdm(train_index):\n",
        "        noise = torch.randn(BATCH_SIZE, 128, 6, 6, device=DEVICE)\n",
        "        \n",
        "        i+=1\n",
        "        \n",
        "        out = torch.topk(patch_distances[\"perception_distances\"][tr_ind], K+1, largest=False).indices\n",
        "        batch = train_tiles[out]\n",
        "        pred = []\n",
        "\n",
        "        for input, x in zip(batch, noise):\n",
        "            input = input.to(DEVICE)\n",
        "            aux = model(x.unsqueeze(0), input.reshape(3,3,56,56), edge_index)\n",
        "            pred.append(aux.unsqueeze(0))\n",
        "            \n",
        "            del aux, input\n",
        "        \n",
        "\n",
        "        pred = torch.cat(pred, dim=0)\n",
        "        target = train_tiles[out].reshape(3, 100, 3, 56, 56).to(DEVICE)\n",
        "        \n",
        "        pcl = 0.8*loss(pred, target[0].reshape(-1, 3, 56, 56))\n",
        "        pcl += 0.1*loss(pred, target[1].reshape(-1, 3, 56, 56))\n",
        "        pcl += 0.1*loss(pred, target[2].reshape(-1, 3, 56, 56))\n",
        "        del pred, noise, target\n",
        "        optimizer.zero_grad()\n",
        "        pcl.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += pcl.item()\n",
        "        \n",
        "    print(\"Percetion Loss: \",running_loss/i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "353c713a",
      "metadata": {},
      "outputs": [],
      "source": [
        "d_model = Discriminator(3, 128)\n",
        "d_model = d_model.to(DEVICE)\n",
        "d_optimizer = torch.optim.Adam(d_model.parameters(), lr = LR)\n",
        "loss_func = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c7fec84a",
      "metadata": {},
      "outputs": [],
      "source": [
        "GAN_DISC_FREQ = 1\n",
        "SWITCH_THRESHOLD = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "27cdca1f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 1.2414074540138245\n",
            "Generator: 2.193467140197754\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.505744993686676\n",
            "Generator: 3.4928207397460938\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.4389732927083969\n",
            "Generator: 4.233623504638672\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.11043206602334976\n",
            "Generator: 4.988692760467529\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.054724663496017456\n",
            "Generator: 5.647676944732666\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.04365951754152775\n",
            "Generator: 5.272009372711182\n",
            "Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.03304153401404619\n",
            "Generator: 6.37879753112793\n",
            "Epoch: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.010769801796413958\n",
            "Generator: 5.964209079742432\n",
            "Epoch: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.016175174852833152\n",
            "Generator: 4.936518669128418\n",
            "Epoch: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.002155388123355806\n",
            "Generator: 7.7889404296875\n",
            "Epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.011214772006496787\n",
            "Generator: 6.1758012771606445\n",
            "Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00489282701164484\n",
            "Generator: 7.668049335479736\n",
            "Epoch: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0014931207988411188\n",
            "Generator: 7.87019157409668\n",
            "Epoch: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.007296571042388678\n",
            "Generator: 6.401513576507568\n",
            "Epoch: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.003975187508331146\n",
            "Generator: 6.489041805267334\n",
            "Epoch: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0017599401180632412\n",
            "Generator: 7.104407787322998\n",
            "Epoch: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.003878734161844477\n",
            "Generator: 6.537299156188965\n",
            "Epoch: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.02502065058797598\n",
            "Generator: 4.781481742858887\n",
            "Epoch: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00011057016672566533\n",
            "Generator: 10.320405006408691\n",
            "Epoch: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00019927031098632142\n",
            "Generator: 9.616630554199219\n",
            "Epoch: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0013983407097839518\n",
            "Generator: 6.839898586273193\n",
            "Epoch: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00536959117744118\n",
            "Generator: 7.466530799865723\n",
            "Epoch: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.002960835467092693\n",
            "Generator: 7.390297889709473\n",
            "Epoch: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0014340333145810291\n",
            "Generator: 7.318933010101318\n",
            "Epoch: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0012082316943633487\n",
            "Generator: 7.159295082092285\n",
            "Epoch: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.036212548166417946\n",
            "Generator: 5.0504608154296875\n",
            "Epoch: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 1.0225704954791581e-05\n",
            "Generator: 12.762008666992188\n",
            "Epoch: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 3.593683800318104e-05\n",
            "Generator: 12.756393432617188\n",
            "Epoch: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0002065138796751853\n",
            "Generator: 10.101375579833984\n",
            "Epoch: 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.001870240934067624\n",
            "Generator: 6.4753289222717285\n",
            "Epoch: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0012003449955955148\n",
            "Generator: 7.93938684463501\n",
            "Epoch: 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0011321202237013495\n",
            "Generator: 8.067837715148926\n",
            "Epoch: 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 4.6280792957986705e-05\n",
            "Generator: 10.390185356140137\n",
            "Epoch: 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.000528591498834885\n",
            "Generator: 7.717127323150635\n",
            "Epoch: 34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.001260030633147835\n",
            "Generator: 7.268249988555908\n",
            "Epoch: 35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.08833332371432334\n",
            "Generator: 5.608023643493652\n",
            "Epoch: 36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 3.113792172371177e-05\n",
            "Generator: 11.93777847290039\n",
            "Epoch: 37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 4.69319820695091e-06\n",
            "Generator: 13.154242515563965\n",
            "Epoch: 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 1.7626097815082176e-05\n",
            "Generator: 11.31515121459961\n",
            "Epoch: 39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00022404309405033018\n",
            "Generator: 8.464252471923828\n",
            "Epoch: 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0012128702969107508\n",
            "Generator: 7.10510778427124\n",
            "Epoch: 41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0005886229773750529\n",
            "Generator: 7.974277019500732\n",
            "Epoch: 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.001241186816400841\n",
            "Generator: 7.199649333953857\n",
            "Epoch: 43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.000655515421385644\n",
            "Generator: 7.775064468383789\n",
            "Epoch: 44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0007437310850946233\n",
            "Generator: 7.7161865234375\n",
            "Epoch: 45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0012624435969428305\n",
            "Generator: 6.229961395263672\n",
            "Epoch: 46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00015702589757893293\n",
            "Generator: 9.399651527404785\n",
            "Epoch: 47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 7.131960956030525e-05\n",
            "Generator: 10.412482261657715\n",
            "Epoch: 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0011436157583375461\n",
            "Generator: 6.62180757522583\n",
            "Epoch: 49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00034826723822334316\n",
            "Generator: 8.61430549621582\n",
            "Epoch: 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00013288394575283746\n",
            "Generator: 9.028534889221191\n",
            "Epoch: 51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0007132355586350059\n",
            "Generator: 7.396597862243652\n",
            "Epoch: 52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0005089287407145093\n",
            "Generator: 7.968942165374756\n",
            "Epoch: 53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0005422827150027842\n",
            "Generator: 7.770041465759277\n",
            "Epoch: 54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0004551634606286825\n",
            "Generator: 8.055424690246582\n",
            "Epoch: 55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0006142466590972617\n",
            "Generator: 7.5646562576293945\n",
            "Epoch: 56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00047167334400910477\n",
            "Generator: 8.06689453125\n",
            "Epoch: 57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0003491759271128103\n",
            "Generator: 8.476754188537598\n",
            "Epoch: 58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0035471985465846956\n",
            "Generator: 7.844437122344971\n",
            "Epoch: 59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0007086462210281752\n",
            "Generator: 7.738935470581055\n",
            "Epoch: 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0007129008154151961\n",
            "Generator: 8.463762283325195\n",
            "Epoch: 61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.0008878943990566768\n",
            "Generator: 7.4089579582214355\n",
            "Epoch: 62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:56<00:00,  5.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrimor: 0.00021371504226408433\n",
            "Generator: 8.798449516296387\n",
            "Epoch: 63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|      | 4/10 [00:28<00:42,  7.06s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     d_g_loss \u001b[38;5;241m=\u001b[39m loss_func(d_g_pred, label)\n\u001b[1;32m     58\u001b[0m     dgl \u001b[38;5;241m=\u001b[39m d_g_loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 60\u001b[0m     \u001b[43md_g_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m SWITCH_THRESHOLD \u001b[38;5;129;01mand\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39mGAN_FREQ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
            "File \u001b[0;32m~/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/ms_thesis_Env/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\",epoch)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    train_index = np.array([[x for x in range(train_tiles.shape[0])] for _ in range(K+1)])\n",
        "    for tr_ind in train_index:\n",
        "        np.random.shuffle(tr_ind)\n",
        "\n",
        "    train_index = train_index.T[:1000].reshape(-1,BATCH_SIZE,K+1)\n",
        "    i=0\n",
        "    \n",
        "    for tr_ind in tqdm(train_index):\n",
        "        noise = torch.randn(BATCH_SIZE, 128, 6, 6, device=DEVICE)\n",
        "        i+=1\n",
        "        \n",
        "        batch = train_tiles[tr_ind]\n",
        "        pred = []\n",
        "\n",
        "        for input, x in zip(batch, noise):\n",
        "            input = input.to(DEVICE)\n",
        "            aux = model(x.unsqueeze(0), input.reshape(3,3,56,56), edge_index)\n",
        "            pred.append(aux)\n",
        "            del aux, input\n",
        "\n",
        "        pred = torch.cat(pred, dim=0)\n",
        "        tr_ind = tr_ind.T.copy() \n",
        "        tr_ind = torch.from_numpy(tr_ind)\n",
        "\n",
        "        label = torch.full((BATCH_SIZE,), REAL_LABEL, dtype=torch.float, device=DEVICE)\n",
        "        for p in d_model.parameters():\n",
        "            p.requires_grad = True\n",
        "        \n",
        "        target = train_tiles[tr_ind][0].reshape(BATCH_SIZE, 3, 56, 56).to(DEVICE)\n",
        "        \n",
        "        d_real_pred = d_model(target).view(-1)\n",
        "        d_real_loss = loss_func(d_real_pred, label)\n",
        "        drl = d_real_loss.mean().item()\n",
        "        \n",
        "        label_fake = torch.full((BATCH_SIZE,), FAKE_LABEL, dtype=torch.float, device=DEVICE)\n",
        "        d_fake_pred = d_model(pred.detach().reshape(100,3,56,56)).view(-1)\n",
        "        d_fake_loss = loss_func(d_fake_pred, label_fake)\n",
        "        dfl = d_fake_loss.mean().item()\n",
        "\n",
        "        if epoch%GAN_DISC_FREQ == 0.0:\n",
        "            d_loss = (d_real_loss + d_fake_loss)/2\n",
        "            d_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "        \n",
        "        for p in d_model.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        d_g_pred = d_model(pred.reshape(100,3,56,56)).view(-1)\n",
        "        del pred\n",
        "        d_g_loss = loss_func(d_g_pred, label)\n",
        "        dgl = d_g_loss.mean().item()\n",
        "        \n",
        "        d_g_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "    if epoch >= SWITCH_THRESHOLD and epoch%GAN_FREQ == 0.0:\n",
        "        print(\"Discrimor:\", dfl+drl)\n",
        "        print(\"Generator:\", dgl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19ee8ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_tiles[tr_ind].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb6916c",
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f3a573",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch:\",epoch)\n",
        "    running_loss = 0.0\n",
        "    train_index = np.array([x for x in range(train_tiles.shape[0])])\n",
        "    np.random.shuffle(train_index)\n",
        "    train_index = train_index[:1000].reshape(-1, BATCH_SIZE)\n",
        "    for tr_ind in tqdm(train_index):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        out = torch.topk(patch_distances[\"perception_distances\"][tr_ind], K+1, largest=False).indices\n",
        "        batch = train_tiles[out]\n",
        "        pred = []\n",
        "\n",
        "        for input in batch:\n",
        "            aux = model(input.reshape(3,3,56,56), edge_index)\n",
        "            pred.append(aux)\n",
        "            del aux, input\n",
        "\n",
        "        pred = torch.cat(pred, dim=0)\n",
        "        out = out.cpu().numpy()\n",
        "        out = out.T.copy() \n",
        "        out = torch.from_numpy(out).to(DEVICE)\n",
        "        \n",
        "        pcl = 0.333*loss(pred, train_tiles[out][0].reshape(-1, 3, 56, 56))\n",
        "        pcl += 0.333*loss(pred, train_tiles[out][1].reshape(-1, 3, 56, 56))\n",
        "        pcl += 0.333*loss(pred, train_tiles[out][2].reshape(-1, 3, 56, 56))\n",
        "        del pred\n",
        "        pcl.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += pcl.item()\n",
        "        \n",
        "    print(\"Percetion Loss: \",running_loss/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6f67fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_tiles[out].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6a427b",
      "metadata": {},
      "outputs": [],
      "source": [
        "i=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1548aabe",
      "metadata": {},
      "outputs": [],
      "source": [
        "out_euc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91e17ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "#i+=1\n",
        "out_per = torch.topk(patch_distances[\"perception_distances\"][train_index[0]][i], K+1, largest=False).indices[1::]\n",
        "out_euc = torch.topk(patch_distances[\"euclidean_distances\"][train_index[0]][i], K+1, largest=False).indices[1::]\n",
        "print(train_index[0][i])\n",
        "print(out_per)\n",
        "print(out_euc)\n",
        "out = torch.cat([out_per,out_euc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340f5841",
      "metadata": {},
      "outputs": [],
      "source": [
        "out.shape[0]>3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2060e886",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.topk(patch_distances[\"perception_distances\"][train_index[0]], K+1, largest=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0692853",
      "metadata": {},
      "source": [
        "# Gen Model Training Loop (2nd Stage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b35b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OgVIVRvGLAFc",
      "metadata": {
        "id": "OgVIVRvGLAFc"
      },
      "outputs": [],
      "source": [
        "model = FullModel(16 ,N_SHOTS, NUM_BLOCK_LOOPS, NUM_BLOCKS_PER_HEAD, 3, 48, 7, 4)\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lrToldw5MqYv",
      "metadata": {
        "id": "lrToldw5MqYv"
      },
      "outputs": [],
      "source": [
        "d_model = Discriminator(3, 512)\n",
        "d_model = d_model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kZWAZF9_gmgE",
      "metadata": {
        "id": "kZWAZF9_gmgE"
      },
      "outputs": [],
      "source": [
        "model = FullModel(16 ,N_SHOTS, NUM_BLOCK_LOOPS, NUM_BLOCKS_PER_HEAD, 3, 48, 7, 4)\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
        "d_optimizer = torch.optim.Adam(d_model.parameters(), lr = LR)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "mse_loss_func = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FePL-wH7kkxt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FePL-wH7kkxt",
        "outputId": "cf96f08d-8879-4a47-f497-2d3d0c06b401"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  print(epoch)\n",
        "  B,T,H,W,C = all_query_tiles.shape\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  count = 0\n",
        "  #graph_indeces = np.random.choice(np.array([x for x in range(B)]),\n",
        "  #                                 size=GRAPH_BATCH_SIZE, replace=False)\n",
        "\n",
        "  train_indeces = np.random.choice(np.array([x for x in range(B)]),\n",
        "                                   size=EPOCH_BATCH_SIZE, replace=False)\n",
        "  train_indeces = train_indeces.reshape(-1, TRAIN_BATCH_SIZE)\n",
        "\n",
        "\n",
        "  graph_sample = train_tiles.reshape(-1, 3, 56, 56)\n",
        "  graph_sample = graph_sample.unsqueeze(0).expand(TRAIN_BATCH_SIZE, -1, 3, 56, 56)\n",
        "  #B,_,H,W,C = graph_sample.shape\n",
        "  #graph_sample = graph_sample.reshape(B*T,C,H,W)\n",
        "\n",
        "  for i in train_indeces:\n",
        "    #query_tiles = all_query_tiles[i].reshape(TRAIN_BATCH_SIZE, T,C,H,W)\n",
        "    query_img = train_images[i].reshape(TRAIN_BATCH_SIZE, 3,224,224)\n",
        "\n",
        "    input = graph_sample #torch.cat([query_tiles, graph_sample], dim=1)\n",
        "\n",
        "    indeces = torch.Tensor([x for x in range(input.shape[0]-16)])\n",
        "    query_img = query_img.to(DEVICE)\n",
        "    input = input.to(DEVICE)\n",
        "\n",
        "    if epoch>SWITCH_THRESHOLD:\n",
        "      d_optimizer.zero_grad()\n",
        "\n",
        "      label = torch.full((TRAIN_BATCH_SIZE,), REAL_LABEL, dtype=torch.float, device=DEVICE)\n",
        "      d_real_pred = d_model(query_img).view(-1)\n",
        "      d_real_loss = loss_func(d_real_pred, label)\n",
        "      drl = d_real_loss.mean().item()\n",
        "\n",
        "    pred = []\n",
        "\n",
        "    for j in tqdm(input):\n",
        "      aux = model(query_img, j, T, NUM_NEIGHBORS, EDGE_METHOD)\n",
        "      pred.append(aux)\n",
        "      del aux\n",
        "\n",
        "    pred = torch.cat(pred, dim=0)\n",
        "\n",
        "    if epoch > SWITCH_THRESHOLD:\n",
        "\n",
        "      label_fake = torch.full((TRAIN_BATCH_SIZE,), FAKE_LABEL, dtype=torch.float, device=DEVICE)\n",
        "      d_fake_pred = d_model(pred.detach()).view(-1)\n",
        "      d_fake_loss = loss_func(d_fake_pred,label_fake)\n",
        "      dfl = d_fake_loss.mean().item()\n",
        "\n",
        "      d_loss = (d_real_loss + d_fake_loss)/2\n",
        "      d_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      d_g_pred = d_model(pred).view(-1)\n",
        "      d_g_loss = loss_func(d_g_pred, label)\n",
        "      dgl = d_g_loss.mean().item()\n",
        "\n",
        "    #g_mse_loss = mse_loss_func(pred, query_img)\n",
        "    #gml = g_mse_loss.mean().item()\n",
        "\n",
        "    if epoch > SWITCH_THRESHOLD:\n",
        "\n",
        "      #g_loss = d_g_loss# + g_mse_loss*0.75\n",
        "      #g_loss.backward()\n",
        "      d_g_loss.backward()\n",
        "      optimizer.step()\n",
        "      print(\"Discrimor:\", dfl+drl)\n",
        "      print(\"Generator:\", dgl)\n",
        "      #print(\"Generator MSE:\", gml)\n",
        "\n",
        "    else:\n",
        "      #g_mse_loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(\"Generator:\", gml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KfJwzUhUmcvJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfJwzUhUmcvJ",
        "outputId": "990bca59-ba1c-48ea-ad3b-608715ec5707"
      },
      "outputs": [],
      "source": [
        "pred.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h3VWb52uzpoG",
      "metadata": {
        "id": "h3VWb52uzpoG"
      },
      "outputs": [],
      "source": [
        "i = 25\n",
        "B,T,H,W,C = all_query_tiles.shape\n",
        "query_tiles = all_query_tiles[i].reshape(T,C,H,W)\n",
        "query_img = train_images[i].reshape(1,3,224,224)\n",
        "mask = torch.arange(train_images.shape[0]) != i\n",
        "graph_sample = train_tiles.reshape(-1, 3, 56, 56)\n",
        "input = torch.cat([query_tiles, graph_sample], dim=0)\n",
        "\n",
        "indeces = torch.Tensor([x for x in range(input.shape[0]-16)])\n",
        "query_img = query_img.to(DEVICE)\n",
        "input = input.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vJsdkx6-lJD4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJsdkx6-lJD4",
        "outputId": "4cada42c-7216-4ee5-dec4-2b3ebb24d56d"
      },
      "outputs": [],
      "source": [
        "print(query_img.shape)\n",
        "print(input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01N_BmZhlduW",
      "metadata": {
        "id": "01N_BmZhlduW"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  out = model(query_img, input, T, NUM_NEIGHBORS, EDGE_METHOD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BMpQUOmtuITS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMpQUOmtuITS",
        "outputId": "5a217379-192c-42eb-c770-ade39895ebc3"
      },
      "outputs": [],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CA28jzWOuSgJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "CA28jzWOuSgJ",
        "outputId": "faf8f231-9f6a-458e-b4bc-e05175f03aef"
      },
      "outputs": [],
      "source": [
        "plt.imshow(out.reshape(224,224,3).detach().cpu().numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SZJP6UqLoLvy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "SZJP6UqLoLvy",
        "outputId": "8419169e-64d2-41e8-c062-298e9ecf58de"
      },
      "outputs": [],
      "source": [
        "plt.imshow(query_img.reshape(224,224,3).detach().cpu().numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l0ZvKlb03Mkr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "l0ZvKlb03Mkr",
        "outputId": "d18a45d3-eeca-4d7d-fc92-49eb3e0fc4c8"
      },
      "outputs": [],
      "source": [
        "for i in range(train_images.shape[0]):\n",
        "  with torch.no_grad():\n",
        "    B,T,H,W,C = train_tiles.shape\n",
        "    query_img = train_tiles[i].reshape(T,C,H,W)\n",
        "    mask = torch.arange(train_images.shape[0]) != i\n",
        "    graph_sample = train_tiles[np.random.choice(train_index[mask], NUM_SAMPLES_PER_GRAPH, replace=False)]\n",
        "    B,_,H,W,C = graph_sample.shape\n",
        "    graph_sample = graph_sample.reshape(B*T,C,H,W)\n",
        "    input = torch.cat([query_img, graph_sample], dim=0)\n",
        "    indeces = torch.Tensor([x for x in range(input.shape[0]-16)])\n",
        "\n",
        "  #Insert Stem Model to get embeddings\n",
        "\n",
        "  for loop in range(NUM_BLOCK_LOOPS):\n",
        "    input = model(input, T, NUM_NEIGHBORS, EDGE_METHOD)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      input, t_indeces = get_past_threshold(input, T, DELETION_THRESHOLD)\n",
        "      indeces = indeces[t_indeces]\n",
        "\n",
        "  n_shot_indices = []\n",
        "  with torch.no_grad():\n",
        "    full_set, shot_set, remaining_indeces, shot_indices = get_multi_shot_set(input, T, N_SHOTS)\n",
        "    for shot in shot_indices:\n",
        "      n_shot_indices.append(indeces[shot])\n",
        "    n_shot_indices = torch.Tensor(np.array(n_shot_indices)).to(torch.int)\n",
        "    indeces = indeces[remaining_indeces]\n",
        "\n",
        "\n",
        "  #Insert Generative Model\n",
        "\n",
        "\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WI1BeY_UjXLw",
      "metadata": {
        "id": "WI1BeY_UjXLw"
      },
      "outputs": [],
      "source": [
        "full_set, shot_set, remaining_indeces, shot_indices  = get_multi_shot_set(input, T, N_SHOTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dkD3v09P3gQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dkD3v09P3gQ",
        "outputId": "2ca8d3ee-17a8-4d9c-bd4b-94dc1b9a49f9"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n0g0g49ZP6gG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0g0g49ZP6gG",
        "outputId": "b80f4126-d007-4a96-b141-842b17401f69"
      },
      "outputs": [],
      "source": [
        "train_tiles.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3db1QXwFov21",
      "metadata": {
        "id": "3db1QXwFov21"
      },
      "outputs": [],
      "source": [
        "n_shot_indices=[]\n",
        "with torch.no_grad():\n",
        "  for shot in shot_indices:\n",
        "      n_shot_indices.append(indeces[shot])\n",
        "  n_shot_indices = torch.Tensor(np.array(n_shot_indices)).to(torch.int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B0K2hIGNo8Qz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0K2hIGNo8Qz",
        "outputId": "8001a018-8aa2-4aa6-cbbc-990020a95467"
      },
      "outputs": [],
      "source": [
        "n_shot_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y5MurnpSjeA4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5MurnpSjeA4",
        "outputId": "04c4e44f-6b02-40e4-a371-f4b4c98a97eb"
      },
      "outputs": [],
      "source": [
        "shot_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3qAz8xQ4f8Uw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qAz8xQ4f8Uw",
        "outputId": "d0f6de1f-b48b-4b1d-8f58-b78c0beef799"
      },
      "outputs": [],
      "source": [
        "full_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oX82-lE6gB2o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX82-lE6gB2o",
        "outputId": "93e30e0f-c279-4cc6-b51c-356639b11e93"
      },
      "outputs": [],
      "source": [
        "shot_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7vX-OkXHgJwA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vX-OkXHgJwA",
        "outputId": "2d4f609f-730c-47c1-c99b-10174e802b91"
      },
      "outputs": [],
      "source": [
        "indeces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wiblbg0GXfDa",
      "metadata": {
        "id": "Wiblbg0GXfDa"
      },
      "outputs": [],
      "source": [
        "grapher_model = Grapher(3, 4).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DHGDg2yWXpye",
      "metadata": {
        "id": "DHGDg2yWXpye"
      },
      "outputs": [],
      "source": [
        "out = grapher_model(input, NUM_NEIGHBORS, EDGE_METHOD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iM5sTJIhdP2_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM5sTJIhdP2_",
        "outputId": "6d923d33-779b-4325-c3e4-843a028caa13"
      },
      "outputs": [],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ogS_9SqvkfYa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogS_9SqvkfYa",
        "outputId": "80e7c904-c175-4162-a5cf-0b53bbc9fc28"
      },
      "outputs": [],
      "source": [
        "indeces.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qGXsS74smDVt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGXsS74smDVt",
        "outputId": "1e384006-c3d0-47f9-b33d-db92f0c73934"
      },
      "outputs": [],
      "source": [
        "indeces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YE4SDo_5kwC8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE4SDo_5kwC8",
        "outputId": "27e51e9b-6586-45bf-e0b1-a93c705d2adf"
      },
      "outputs": [],
      "source": [
        "t_indeces.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u9YpBWeQlEA3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9YpBWeQlEA3",
        "outputId": "95a291a5-f4cf-4cce-e4f6-76ca91427829"
      },
      "outputs": [],
      "source": [
        "graph_sample[indeces.to(torch.int)].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JBvj3DrRGlUX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBvj3DrRGlUX",
        "outputId": "c1b316e3-0da1-4adc-f785-8d4a3af72661"
      },
      "outputs": [],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g7DHsMzqkFTC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7DHsMzqkFTC",
        "outputId": "b30e3111-8a18-4669-ba50-b5425d7b97cf"
      },
      "outputs": [],
      "source": [
        "shot_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zcD3ytQeTRfG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcD3ytQeTRfG",
        "outputId": "7a2eedf9-b3fd-47b4-f7c2-cb271b628b32"
      },
      "outputs": [],
      "source": [
        "full_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z-YB6bhuDs4C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-YB6bhuDs4C",
        "outputId": "3f5b141e-707e-45f8-9e23-8ace38fae400"
      },
      "outputs": [],
      "source": [
        "T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Bn4ywD_GvaG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bn4ywD_GvaG",
        "outputId": "f97a4b97-2a52-4883-83a2-f519957d0a3c"
      },
      "outputs": [],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IYiBnhCr_9bk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYiBnhCr_9bk",
        "outputId": "f19ba2bc-9738-4407-98fc-8f037263ae0b"
      },
      "outputs": [],
      "source": [
        "graph_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l4yVxS9HACwu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4yVxS9HACwu",
        "outputId": "40c2932d-6450-40b4-d850-98adafc11b89"
      },
      "outputs": [],
      "source": [
        "query_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4HTpoHS_EDSF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HTpoHS_EDSF",
        "outputId": "f2297dce-3e41-43b6-f36f-b9deae280976"
      },
      "outputs": [],
      "source": [
        "input.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ms_thesis_Env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
