{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91b3e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "from torch_geometric.data import Dataset, download_url, Data\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.sampler import BaseSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6dcfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"C://Austin//Projects//MS_Thesis_Data//base_gnn_testing_root//processed//data_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd9a211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(Dataset): #For this ds I have ald done all the required pre prcessing \n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, data_dict = None):\n",
    "        self.data_dict = data_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        print(self.raw_dir)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return np.array([os.path.join(self.raw_dir, x) for x in self.data_dict[\"name\"]])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return \"not_implemented.pt\"\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        idx = -1\n",
    "\n",
    "        # Process pre made data dictionary\n",
    "\n",
    "        x = np.append(self.data_dict[\"features\"], self.data_dict[\"centroids\"], axis=0)\n",
    "        \n",
    "        y = np.append(self.data_dict[\"cluster\"], np.array([0,1,2,3,4]), axis=0)\n",
    "        \n",
    "        edge_map = []\n",
    "\n",
    "\n",
    "        i=-1\n",
    "        for cluster in y[:127]:\n",
    "            i+=1\n",
    "            edge_map.append([np.int64(i), np.int64(cluster+self.data_dict[\"features\"].shape[0])])\n",
    "            #edge_map.append([np.int64(cluster+self.data_dict[\"features\"].shape[0]), np.int64(i)])\n",
    "        \n",
    "\n",
    "        i+=1\n",
    "        for centroid1 in y[i:-1]:\n",
    "            for centroid2 in y[i+1:]:\n",
    "                edge_map.append([np.int64(centroid1+self.data_dict[\"features\"].shape[0]), np.int64(centroid2+self.data_dict[\"features\"].shape[0])])\n",
    "                #edge_map.append([np.int64(centroid2+self.data_dict[\"features\"].shape[0]), np.int64(centroid1+self.data_dict[\"features\"].shape[0])])\n",
    "            i+=1\n",
    "\n",
    "        edge_attrs = [] \n",
    "\n",
    "\n",
    "        for edge in edge_map:\n",
    "            edge_attrs.append(distance.euclidean(x[edge[0]], x[edge[1]]))\n",
    "\n",
    "        edge_attrs = np.array(edge_attrs)\n",
    "\n",
    "        edge_attrs = edge_attrs/np.max(edge_attrs)\n",
    "\n",
    "        edge_map_aux = [None,None]\n",
    "        edge_map_aux[0] = [x[0] for x in edge_map]\n",
    "        edge_map_aux[1] = [x[1] for x in edge_map]\n",
    "        edge_map_aux = np.array(edge_map_aux)\n",
    "\n",
    "        # Process pre made data dictionary\n",
    "\n",
    "        x = torch.Tensor(x)\n",
    "        y = torch.Tensor(y)\n",
    "        edge_attrs = torch.Tensor(np.array(edge_attrs))\n",
    "        edge_map_aux = torch.Tensor(np.array(edge_map_aux)).to(torch.int64)\n",
    "\n",
    "        data = Data(x, edge_map_aux, edge_attrs, y)\n",
    "\n",
    "        if self.pre_filter is not None and not self.pre_filter(data):\n",
    "            pass\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "        torch.save(data, os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        return self.data_dict[\"name\"].shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e411edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Austin\\Projects\\MS_Thesis_Data\\base_gnn_testing_root\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MyOwnDataset(root = \"C://Austin//Projects//MS_Thesis_Data//base_gnn_testing_root\", data_dict = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b708c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[132, 4096], edge_index=[2, 137], edge_attr=[137], y=[132])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "890159ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cefbdba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[132, 4096], edge_index=[2, 137], edge_attr=[137], y=[132])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
    "            dim=-1\n",
    "        )  # product of a pair of nodes on each edge\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "\n",
    "def train_link_predictor(\n",
    "    model, train_data, optimizer, criterion, n_epochs=100\n",
    "    #, val_data\n",
    "):\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        edge_label_index = torch.cat(\n",
    "            [train_data.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        edge_label = torch.cat([\n",
    "            train_data.edge_label,\n",
    "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #val_auc = eval_link_predictor(model, val_data)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}\")#, Val AUC: {val_auc:.3f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model, data):\n",
    "\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f6b26f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_link_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#test_auc = eval_link_predictor(model, test_data)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"Test: {test_auc:.3f}\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[107], line 46\u001b[0m, in \u001b[0;36mtrain_link_predictor\u001b[1;34m(model, train_data, optimizer, criterion, n_epochs)\u001b[0m\n\u001b[0;32m     37\u001b[0m neg_edge_index \u001b[38;5;241m=\u001b[39m negative_sampling(\n\u001b[0;32m     38\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39medge_index, num_nodes\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39mnum_nodes,\n\u001b[0;32m     39\u001b[0m     num_neg_samples\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m edge_label_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m     42\u001b[0m     [train_data\u001b[38;5;241m.\u001b[39medge_index, neg_edge_index],\n\u001b[0;32m     43\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m edge_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_label\u001b[49m,\n\u001b[0;32m     47\u001b[0m     train_data\u001b[38;5;241m.\u001b[39medge_label\u001b[38;5;241m.\u001b[39mnew_zeros(neg_edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     48\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     50\u001b[0m out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(z, edge_label_index)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, edge_label)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch_geometric\\data\\data.py:561\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch_geometric\\data\\storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'edge_label'"
     ]
    }
   ],
   "source": [
    "model = Net(dataset.num_features, dataset.num_features//2, dataset.num_features//8).to(\"cpu\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "model = train_link_predictor(model, dataset, optimizer, criterion, n_epochs=1)\n",
    "\n",
    "#test_auc = eval_link_predictor(model, test_data)\n",
    "#print(f\"Test: {test_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1772a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GCNConv(4096, 2048)\n",
      "  (conv2): GCNConv(2048, 512)\n",
      ")\n",
      "Number of parameters:  9439744\n"
     ]
    }
   ],
   "source": [
    "model = Net(dataset.num_features, dataset.num_features//2, dataset.num_features//8).to(\"cpu\")\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cf2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.8741e-01,  4.3697e-01,  1.6317e+00, -1.6259e+00, -5.1332e-04,\n",
       "         3.6588e-01,  1.2880e-01,  2.2605e+00, -1.9703e-01,  2.4138e-01,\n",
       "         1.7142e-01, -8.9749e-01, -4.9346e-01,  2.2433e+00,  2.2167e-02,\n",
       "         1.3420e-01,  1.4354e+00, -4.2092e-01, -1.0728e+00,  1.3446e+00,\n",
       "        -5.6346e-01, -2.1791e-01, -3.7950e-01, -1.1852e+00,  2.5461e-01,\n",
       "         1.1167e+00,  1.3299e-01,  2.5837e-01,  3.4525e-01, -9.3704e-01,\n",
       "         2.3742e+00,  1.9445e+00, -9.8799e-01, -2.3600e-02,  4.6015e-01,\n",
       "        -1.1712e+00,  7.9486e-01, -7.1922e-01,  1.7959e+00,  2.5094e-01,\n",
       "        -1.4819e+00, -4.9602e-01, -1.0645e+00,  1.3196e+00, -2.9403e-01,\n",
       "         5.3875e-01,  1.9642e-01, -1.5188e+00,  7.1758e-01, -2.1441e-01,\n",
       "        -1.4755e+00, -6.8343e-01, -1.1784e+00,  1.2444e+00, -5.0079e-01,\n",
       "         6.6117e-01, -9.1243e-01,  6.1809e-01,  1.4038e+00, -1.0875e+00,\n",
       "        -5.9860e-01, -9.6111e-01, -5.5544e-01, -2.6084e-01, -1.0332e+00,\n",
       "         7.6523e-01, -1.0081e-02,  6.9663e-01, -2.6156e-01, -7.8395e-02,\n",
       "         1.2274e+00, -8.6992e-01, -1.1362e+00,  1.2367e-01,  1.3897e+00,\n",
       "        -8.5220e-02, -2.9473e-01,  1.3523e+00, -7.8398e-01,  1.9896e+00,\n",
       "         1.0568e+00,  4.4950e-01,  1.2846e-01, -1.1684e+00,  3.9744e-01,\n",
       "         1.5838e+00,  8.2403e-03, -5.1011e-01, -1.0075e+00,  1.8834e+00,\n",
       "        -3.7834e-01,  6.0212e-01,  5.5663e-01, -5.7154e-01, -3.8974e-01,\n",
       "        -2.4135e+00,  7.7420e-01,  2.9011e-01,  2.4956e-01,  1.2915e+00,\n",
       "         2.0923e-01, -2.7473e-01, -4.1225e-01,  2.0754e-01,  7.1445e-01,\n",
       "        -6.4065e-01, -1.6660e-01, -3.3318e-01, -1.2777e-02, -6.4378e-01,\n",
       "         7.2578e-01,  2.3373e+00, -1.8426e-01, -2.8195e-01,  1.8250e+00,\n",
       "        -7.7408e-01, -1.4399e+00, -1.7503e-01, -3.3387e-01, -1.1745e+00,\n",
       "         1.0127e+00,  3.8805e-01, -7.4016e-02, -1.3757e+00, -4.5529e-01,\n",
       "         6.2381e-01,  2.0040e-01, -1.8711e+00, -4.7227e-01, -4.8803e-01,\n",
       "         5.4954e-01,  4.9706e-01, -6.3272e-01,  1.2907e+00, -2.1708e-01,\n",
       "         1.9754e+00, -5.1856e-01, -1.8747e-01,  7.3134e-01,  2.4218e-01,\n",
       "        -8.7861e-01, -9.3732e-02,  4.2221e-01, -4.2470e-01,  1.2634e+00,\n",
       "         1.0391e-01, -6.5737e-01,  3.5449e-02,  2.0755e-01, -2.3048e-01,\n",
       "        -8.0722e-01, -4.0020e-01, -4.5169e-01,  3.1536e-01,  7.3228e-01,\n",
       "        -3.6928e-02,  6.6156e-01,  5.4954e-01, -4.6899e-01,  4.8650e-01,\n",
       "        -4.4029e-01, -8.5140e-01, -2.3578e-01,  1.1955e+00, -1.6089e-01,\n",
       "         4.5556e-01,  2.9632e-01,  6.9637e-03, -2.5365e-01,  7.2689e-01,\n",
       "        -2.6782e-01, -4.4139e-01,  6.4003e-01,  3.0469e-01, -2.2210e-01,\n",
       "        -8.9702e-01, -5.8946e-01, -1.5615e-01, -4.8952e-01,  5.2800e-01,\n",
       "        -1.1639e+00,  1.8952e-01,  8.0014e-01,  8.0586e-01, -2.1024e-01,\n",
       "        -6.5820e-01,  1.9262e-01,  8.2231e-01, -5.0795e-01,  7.8392e-04,\n",
       "        -1.5304e+00,  6.0691e-01, -1.0447e+00,  3.6637e-02,  3.4793e-01,\n",
       "        -1.1390e-01,  2.5530e+00, -5.1496e-01,  1.0521e-01,  7.8861e-01,\n",
       "         2.5500e-01,  4.4368e-01, -5.8656e-01, -3.8825e-01,  4.5901e-01,\n",
       "        -5.9065e-01,  7.2380e-01, -1.2465e+00, -1.9100e-01,  8.0212e-01,\n",
       "         1.5636e+00, -1.6697e-01,  5.3062e-01, -1.1927e+00, -1.4279e+00,\n",
       "         1.2868e+00, -1.7498e-01,  9.2865e-01, -7.8856e-01, -2.6177e-01,\n",
       "        -4.7691e-01, -1.4607e-01,  1.1128e+00,  5.7866e-01,  2.4972e-01,\n",
       "        -1.0897e+00,  1.6057e+00,  5.5609e-01, -1.6331e+00,  8.3357e-01,\n",
       "         8.1354e-01,  1.0713e-02, -3.1778e-01,  1.2079e-01, -1.1122e-02,\n",
       "         1.2849e+00,  1.0027e+00, -7.0994e-01,  2.9551e-02, -4.6163e-01,\n",
       "         1.0273e+00,  4.7383e-01, -1.0567e+00, -6.6178e-01, -8.7765e-01,\n",
       "        -9.6629e-01, -2.9409e-01, -1.8645e-01,  1.1631e+00,  1.8825e-02,\n",
       "        -5.1620e-01, -4.6198e-01,  1.2956e+00,  5.3824e-01, -1.2980e+00,\n",
       "         1.5923e+00, -9.9283e-01,  7.9901e-01, -8.4590e-01, -7.4199e-01,\n",
       "        -1.5548e+00, -5.5413e-01,  2.3052e+00, -8.4365e-01,  1.7102e-01,\n",
       "        -6.1563e-01,  1.6505e-01, -4.3681e-01, -1.1494e+00, -1.4490e-01,\n",
       "        -1.7228e+00,  1.6031e+00,  7.2044e-01, -2.8724e-01, -2.5030e-01,\n",
       "         1.4000e+00,  8.8952e-01,  5.4312e-01,  3.1584e-02, -1.4442e-01,\n",
       "        -4.6752e-02,  8.6270e-02,  1.4119e-01, -1.7957e+00,  7.6386e-01,\n",
       "        -3.3057e-01,  9.4801e-01,  4.5899e-01, -2.6538e-01, -3.9720e-01,\n",
       "         1.6570e-01, -8.0437e-02,  1.1127e+00,  3.2501e-01, -9.8352e-01,\n",
       "        -3.7746e-01,  2.2757e+00,  3.1429e-01, -4.1533e-01,  4.0754e-01,\n",
       "         1.4104e+00, -1.7801e+00, -1.3459e-01,  2.8402e-01,  3.5649e-01,\n",
       "         2.3839e-01,  1.4015e-01, -7.7325e-01, -2.0565e+00,  3.7955e-01,\n",
       "         3.3941e-01, -2.0260e+00, -1.6180e+00, -3.0607e-01, -1.4621e-01,\n",
       "        -1.5639e+00,  9.6520e-01,  1.2704e+00,  7.2499e-02, -1.1211e+00,\n",
       "         8.0537e-02,  2.3694e-01,  1.6724e+00,  1.0084e+00,  5.2836e-01,\n",
       "         5.0888e-01,  3.6054e-01,  4.0667e-01,  2.9702e-01,  7.4460e-01,\n",
       "         6.8051e-01, -6.2171e-01,  1.1729e+00, -3.7127e-01, -1.4285e+00,\n",
       "         1.3168e-01,  1.3104e+00, -1.3483e+00,  2.8845e-01,  7.4441e-01,\n",
       "         1.4450e+00, -9.7021e-01,  4.7863e-01, -1.3561e+00, -2.1017e+00,\n",
       "        -8.1947e-01, -9.7314e-01,  5.8126e-01,  6.9981e-01, -8.9467e-01,\n",
       "         5.3574e-01,  7.5181e-01, -1.5430e+00,  2.1459e-01,  1.1943e-01,\n",
       "        -1.9187e-01, -3.5455e-01, -4.3778e-01, -2.7760e-01,  9.0521e-01,\n",
       "         1.9685e-01,  3.3834e-01, -1.3530e-01,  1.7291e+00,  1.1136e-01,\n",
       "        -1.3302e-01, -1.7099e-01,  1.4630e+00, -3.6211e-01,  2.8170e-01,\n",
       "        -2.7089e-01,  2.0330e-01,  1.8411e+00,  6.3266e-01, -2.1632e-01,\n",
       "        -2.5280e-01,  9.2345e-01, -4.8647e-01,  1.7869e+00,  7.1163e-01,\n",
       "         2.7710e-01, -1.2961e+00, -1.6190e+00, -4.8428e-02, -3.1292e-01,\n",
       "        -6.9023e-01, -5.8569e-01,  2.6786e-01, -1.0561e+00, -9.8273e-01,\n",
       "         1.9383e-01, -7.1944e-01,  1.1105e+00,  8.5667e-01, -1.1484e+00,\n",
       "         1.4572e+00, -1.1768e+00, -7.6120e-01, -7.3818e-01, -1.2844e+00,\n",
       "         6.2211e-01,  8.0056e-01,  1.2084e+00,  1.5965e+00, -6.3174e-01,\n",
       "         3.2834e-01, -1.1059e-01, -1.0577e-01,  7.7066e-01,  1.4004e+00,\n",
       "        -1.1194e+00, -5.1655e-01, -1.2056e-01,  7.2208e-01, -7.3665e-01,\n",
       "        -1.2610e+00,  9.6756e-01,  2.8422e-01, -1.4379e+00, -2.7527e-02,\n",
       "         1.1566e+00,  2.4409e-01, -6.3654e-02, -5.9548e-01,  2.4595e-01,\n",
       "         8.7805e-01,  2.2589e-01, -2.0501e-01,  1.8108e-01, -5.2064e-01,\n",
       "         1.3281e-01,  8.3630e-01, -3.0629e-01,  2.3553e-02, -3.5363e-01,\n",
       "         6.9496e-01, -2.0551e+00, -4.7282e-01, -1.4063e+00, -3.5118e-01,\n",
       "         6.3392e-01, -5.7519e-01,  2.2535e-01, -5.1243e-01, -4.7642e-01,\n",
       "         1.8835e-01, -1.4069e-01, -7.2634e-03,  2.5234e-01, -7.0065e-01,\n",
       "         4.4577e-01, -1.0015e+00,  1.0579e+00,  3.6025e-01, -1.5060e+00,\n",
       "         1.0851e-01, -3.5963e-01,  7.6308e-01, -1.8084e+00, -1.6352e+00,\n",
       "        -1.0103e+00,  1.4246e+00, -1.4186e+00, -3.7499e-01,  1.4458e+00,\n",
       "        -9.6889e-01, -5.5929e-01,  1.6025e+00, -1.4886e+00, -9.4653e-01,\n",
       "        -1.6429e-01,  5.5730e-01,  8.1140e-01,  1.2650e-01, -1.4020e+00,\n",
       "         2.8787e-01, -4.1476e-02,  6.1123e-01, -2.1473e-01,  8.5729e-02,\n",
       "        -6.9141e-01,  8.7613e-01, -4.4554e-01,  4.9990e-01, -5.2384e-01,\n",
       "        -1.7905e+00, -1.5564e+00, -1.3657e+00, -1.6340e-01,  3.6494e+00,\n",
       "        -5.6639e-01, -1.5429e-01,  1.9898e-01,  7.0672e-01, -1.1481e+00,\n",
       "         1.9850e+00, -8.3381e-01,  1.4990e+00, -5.8925e-01, -9.2920e-01,\n",
       "        -1.9356e-01, -2.7064e-01,  4.2175e-02, -2.0249e+00,  6.5865e-01,\n",
       "         6.9220e-01, -1.2237e+00, -1.1533e+00,  5.0334e-01,  1.4383e-01,\n",
       "        -1.6567e+00, -7.7888e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(dataset.x, dataset.edge_index)[0]\n",
    "#Output a encoding vector for every node:\n",
    "# Shape = [number_of_nodes, size_of_embedding] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254ff64e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neg_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msparse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch_geometric\\utils\\_negative_sampling.py:103\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[1;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     rnd \u001b[38;5;241m=\u001b[39m sample(population, sample_size, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, idx\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m         mask \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd, neg_idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "neg_edge_index = negative_sampling(dataset.edge_index,dataset.x.shape[0], dataset.edge_index.shape[0], method='sparse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_thesis_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
