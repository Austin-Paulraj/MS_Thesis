{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aac128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "from torch_geometric.data import Dataset, download_url, Data\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import torch\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from torch_geometric import nn as gnn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.sampler import BaseSampler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14c6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C://Austin//Projects//MS_Thesis_Data//test_eye_clusters_extract.pk1', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461140b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'image', 'features', 'factor', 'cluster', 'centroids'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7985b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separated_Dataset(Dataset): #For this ds I have ald done all the required pre prcessing \n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, data_dict = None, num_data = 10, num_nodes = 5):\n",
    "        self.data_dict = data_dict\n",
    "        self.num_data = num_data\n",
    "        self.num_nodes = num_nodes\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return np.array([os.path.join(self.raw_dir, x) for x in self.data_dict[\"name\"]])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return \"not_implemented.pt\"\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        idx = -1\n",
    "\n",
    "        # Process pre made data dictionary\n",
    "\n",
    "        x_features = np.append(self.data_dict[\"features\"], self.data_dict[\"centroids\"], axis=0)\n",
    "        y = np.append(self.data_dict[\"cluster\"], np.array([127,128,129,130,131]), axis=0)\n",
    "        \n",
    "        edge_map = []\n",
    "\n",
    "\n",
    "        i=-1\n",
    "        for cluster in y[:127]:\n",
    "            i+=1\n",
    "            edge_map.append([np.int64(i), np.int64(cluster+self.data_dict[\"features\"].shape[0])])\n",
    "            #edge_map.append([np.int64(cluster+self.data_dict[\"features\"].shape[0]), np.int64(i)])\n",
    "        \n",
    "\n",
    "        i+=1\n",
    "        for centroid1 in y[i:-1]:\n",
    "            for centroid2 in y[i+1:]:\n",
    "                edge_map.append([np.int64(centroid1+self.data_dict[\"features\"].shape[0]), np.int64(centroid2+self.data_dict[\"features\"].shape[0])])\n",
    "                #edge_map.append([np.int64(centroid2+self.data_dict[\"features\"].shape[0]), np.int64(centroid1+self.data_dict[\"features\"].shape[0])])\n",
    "            i+=1\n",
    "\n",
    "        edge_attrs = [] \n",
    "\n",
    "\n",
    "        for edge in edge_map:\n",
    "            edge_attrs.append(1)\n",
    "        \n",
    "        edge_attrs = np.array(edge_attrs)\n",
    "        edge_attrs = np.delete(edge_attrs,1)\n",
    "        edge_attrs = torch.Tensor(edge_attrs)\n",
    "\n",
    "        edge_map_aux = [None,None]\n",
    "        edge_map_aux[0] = [x[0] for x in edge_map]\n",
    "        edge_map_aux[1] = [x[1] for x in edge_map]\n",
    "        edge_map_aux = np.array(edge_map_aux)\n",
    "\n",
    "        for i in range(self.data_dict[\"image\"].shape[0]):\n",
    "            \n",
    "            y = torch.Tensor(self.data_dict[\"image\"][i])\n",
    "\n",
    "            x_temp = np.delete(x_features,i, axis=0)\n",
    "            edge_map_aux_temp = np.delete(edge_map_aux,i, axis = 1)\n",
    "\n",
    "\n",
    "            data = Data(torch.Tensor(x_temp), torch.Tensor(edge_map_aux_temp), edge_attrs, y)\n",
    "\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        return self.data_dict[\"name\"].shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f608ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 4096)\n",
      "(126, 4096)\n",
      "(127, 4096)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(127,4096)\n",
    "print(x.shape)\n",
    "print(np.delete(x,1, axis = 0).shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592c6b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(18, 4096)\n"
     ]
    }
   ],
   "source": [
    "target_cluster = data[\"cluster\"][0]\n",
    "same_clust = np.where(data[\"cluster\"].astype(np.int32)==np.int32(target_cluster))[0]\n",
    "diff_clust = np.where(data[\"cluster\"].astype(np.int32)!=np.int32(target_cluster))[0]\n",
    "same_clust = np.random.choice(same_clust, 7, replace=False)\n",
    "diff_clust = np.random.choice(diff_clust, 7, replace=False)\n",
    "\n",
    "clusts_in_diff = data[\"cluster\"][diff_clust]\n",
    "print(np.unique(clusts_in_diff).shape)\n",
    "x = data[\"features\"][np.append(same_clust,diff_clust)]\n",
    "x = np.append(x, data[\"centroids\"][np.append(target_cluster, np.unique(clusts_in_diff))], axis=0)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aefaf3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 4096)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:14].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88ec73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C://Austin//Projects//MS_Thesis_Data//base_gnn_testing_root//separated_training_set\"\n",
    "dataset = Separated_Dataset(root_path, data_dict=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0791bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Separated_Dataset(127)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ed2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"C://Austin//Projects//MS_Thesis_Data//base_gnn_testing_root//processed//data_0.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_thesis_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
